{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88e9b3f4-302e-48ea-80b7-606232a57b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image, ImageOps\n",
    "import sys\n",
    "import re\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf664e7-d652-4370-9e7f-f48e22c389dc",
   "metadata": {},
   "source": [
    "# Preprocess CSV:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e5f101-a86c-468e-9a88-5853dcdbc621",
   "metadata": {},
   "source": [
    "### Fabric types:\n",
    "  0 denim, 1 cotton, 2 leather, 3 furry, 4 knitted, 5 chiffon, 6 other, 7 NA\n",
    "\n",
    "### Pattern types:\n",
    "  0 floral, 1 graphic, 2 striped, 3 pure color, 4 lattice, 5 other, 6 color block, 7 NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29a456d-e6c9-47c0-bd6d-dd7c89aead23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-45253269/ipykernel_1208531/908819537.py:15: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  keypoints_loc = pd.read_csv('/vast/amr10211/cv_data/keypoints/keypoints_loc.txt', delim_whitespace=True, names=keypoint_headers)\n"
     ]
    }
   ],
   "source": [
    "#Fabric Data:\n",
    "fabric_headers = ['img_name', 'upper_fabric', 'lower_fabric', 'outer_fabric']\n",
    "fabric_ann = pd.read_csv('/vast/amr10211/cv_data/labels/texture/fabric_ann.txt', delimiter=' ', names=fabric_headers)\n",
    "\n",
    "#Pattern Data:\n",
    "pattern_headers = ['img_name', 'upper_pattern', 'lower_pattern', 'outer_pattern']\n",
    "pattern_ann = pd.read_csv('/vast/amr10211/cv_data/labels/texture/pattern_ann.txt', delimiter=' ', names=pattern_headers)\n",
    "\n",
    "#Keypoints Data (for filtering for full body images):\n",
    "keypoint_headers = ['img_name', 'x_1', 'y_1', 'x_2', 'y_2', 'x_3', 'y_3', 'x_4', 'y_4', 'x_5', 'y_5',\n",
    "           'x_6', 'y_6', 'x_7', 'y_7', 'x_8', 'y_8', 'x_9', 'y_9', 'x_10', 'y_10',\n",
    "           'x_11', 'y_11', 'x_12', 'y_12', 'x_13', 'y_13', 'x_14', 'y_14', 'x_15', 'y_15',\n",
    "           'x_16', 'y_16', 'x_17', 'y_17', 'x_18', 'y_18', 'x_19', 'y_19', 'x_20', 'y_20',\n",
    "           'x_21', 'y_21']\n",
    "keypoints_loc = pd.read_csv('/vast/amr10211/cv_data/keypoints/keypoints_loc.txt', delim_whitespace=True, names=keypoint_headers)\n",
    "\n",
    "img_names = keypoints_loc['img_name'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eedcec64-6d93-4513-85d5-c5e234ecb787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge and filter Data\n",
    "\n",
    "data_df = pd.merge(fabric_ann,pattern_ann, on='img_name') #Merge fabric and pattern\n",
    "data_df = data_df[data_df['img_name'].isin(img_names)] #Filter for full body images \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29053adc-9bc2-4713-82cc-0ac85d23caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_id(img_name):\n",
    "    # Find the index of the last dash\n",
    "    last_dash_index = img_name.rfind(\"-\")\n",
    "\n",
    "    # Extract the substring before the last dash\n",
    "    substring_before_last_dash = img_name[:last_dash_index]\n",
    "\n",
    "    return substring_before_last_dash\n",
    "\n",
    "data_df['img_id'] = data_df['img_name'].apply(get_image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e019171d-eff7-4797-b0a8-72c8aef7789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_num(img_name):\n",
    "    # Find the index of the last dash\n",
    "    last_dash_index = img_name.rfind(\"-\")\n",
    "\n",
    "    # Find the index of the next underscore after the last dash\n",
    "    next_underscore_index = img_name.find(\"_\", last_dash_index)\n",
    "\n",
    "    # Extract the substring between the last dash and the next underscore\n",
    "    substring_between_dash_and_underscore = img_name[last_dash_index + 1:next_underscore_index]\n",
    "\n",
    "    return substring_between_dash_and_underscore\n",
    "\n",
    "data_df['img_num'] = data_df['img_name'].apply(get_image_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a143587f-bf00-4460-8dff-f1df1f97f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_view(img_name):\n",
    "    # Find the index of the last dash\n",
    "    last_dash_index = img_name.rfind(\"-\")\n",
    "    \n",
    "    # Find the index of the underscore after the last dash\n",
    "    underscore_index = img_name.find(\"_\", last_dash_index)\n",
    "    \n",
    "    # Find the index of the underscore after the one following the last dash\n",
    "    next_underscore_index = img_name.find(\"_\", underscore_index + 1)\n",
    "    \n",
    "    # Find the index of the period\n",
    "    period_index = img_name.rfind(\".\")\n",
    "    \n",
    "    # Extract the substring between the underscore after the last dash and the period\n",
    "    substring_between_underscores_and_period = img_name[next_underscore_index + 1:period_index]\n",
    "    \n",
    "    return substring_between_underscores_and_period\n",
    "\n",
    "    \n",
    "data_df['img_view'] = data_df['img_name'].apply(get_image_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4452718c-dc98-4b09-9573-9771c370fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segm_name(img_name):\n",
    "    segm_name = img_name[:-4]\n",
    "    segm_name = segm_name + '_segm.png'\n",
    "    return segm_name\n",
    "\n",
    "data_df['segm_name'] = data_df['img_name'].apply(get_segm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb9a210a-1797-4834-a09e-77c5f107d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out images without segmentations:\n",
    "segm_names = os.listdir('/vast/amr10211/cv_data/segm_preprocessed')\n",
    "\n",
    "# Filter out directories, if any\n",
    "segm_names = [segm for segm in segm_names if os.path.isfile(os.path.join('/vast/amr10211/cv_data/segm_preprocessed', segm))]\n",
    "\n",
    "data_df = data_df[data_df['segm_name'].isin(segm_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e176f63f-647e-4279-8869-2d68ef8b00e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>upper_fabric</th>\n",
       "      <th>lower_fabric</th>\n",
       "      <th>outer_fabric</th>\n",
       "      <th>upper_pattern</th>\n",
       "      <th>lower_pattern</th>\n",
       "      <th>outer_pattern</th>\n",
       "      <th>img_id</th>\n",
       "      <th>img_num</th>\n",
       "      <th>img_view</th>\n",
       "      <th>segm_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEN-Denim-id_00000080-01_7_additional.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>MEN-Denim-id_00000080</td>\n",
       "      <td>01</td>\n",
       "      <td>additional</td>\n",
       "      <td>MEN-Denim-id_00000080-01_7_additional_segm.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEN-Denim-id_00000089-01_7_additional.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>MEN-Denim-id_00000089</td>\n",
       "      <td>01</td>\n",
       "      <td>additional</td>\n",
       "      <td>MEN-Denim-id_00000089-01_7_additional_segm.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEN-Denim-id_00000089-02_7_additional.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>MEN-Denim-id_00000089</td>\n",
       "      <td>02</td>\n",
       "      <td>additional</td>\n",
       "      <td>MEN-Denim-id_00000089-02_7_additional_segm.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MEN-Denim-id_00000089-03_7_additional.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>MEN-Denim-id_00000089</td>\n",
       "      <td>03</td>\n",
       "      <td>additional</td>\n",
       "      <td>MEN-Denim-id_00000089-03_7_additional_segm.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEN-Denim-id_00000089-04_7_additional.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>MEN-Denim-id_00000089</td>\n",
       "      <td>04</td>\n",
       "      <td>additional</td>\n",
       "      <td>MEN-Denim-id_00000089-04_7_additional_segm.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44074</th>\n",
       "      <td>WOMEN-Tees_Tanks-id_00007969-04_7_additional.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>WOMEN-Tees_Tanks-id_00007969</td>\n",
       "      <td>04</td>\n",
       "      <td>additional</td>\n",
       "      <td>WOMEN-Tees_Tanks-id_00007969-04_7_additional_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44078</th>\n",
       "      <td>WOMEN-Tees_Tanks-id_00007970-01_7_additional.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>WOMEN-Tees_Tanks-id_00007970</td>\n",
       "      <td>01</td>\n",
       "      <td>additional</td>\n",
       "      <td>WOMEN-Tees_Tanks-id_00007970-01_7_additional_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44082</th>\n",
       "      <td>WOMEN-Tees_Tanks-id_00007976-01_4_full.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>WOMEN-Tees_Tanks-id_00007976</td>\n",
       "      <td>01</td>\n",
       "      <td>full</td>\n",
       "      <td>WOMEN-Tees_Tanks-id_00007976-01_4_full_segm.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44086</th>\n",
       "      <td>WOMEN-Tees_Tanks-id_00007979-03_4_full.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>WOMEN-Tees_Tanks-id_00007979</td>\n",
       "      <td>03</td>\n",
       "      <td>full</td>\n",
       "      <td>WOMEN-Tees_Tanks-id_00007979-03_4_full_segm.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44091</th>\n",
       "      <td>WOMEN-Tees_Tanks-id_00007979-04_4_full.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>WOMEN-Tees_Tanks-id_00007979</td>\n",
       "      <td>04</td>\n",
       "      <td>full</td>\n",
       "      <td>WOMEN-Tees_Tanks-id_00007979-04_4_full_segm.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12701 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               img_name  upper_fabric  \\\n",
       "0             MEN-Denim-id_00000080-01_7_additional.jpg             1   \n",
       "1             MEN-Denim-id_00000089-01_7_additional.jpg             1   \n",
       "2             MEN-Denim-id_00000089-02_7_additional.jpg             1   \n",
       "3             MEN-Denim-id_00000089-03_7_additional.jpg             1   \n",
       "4             MEN-Denim-id_00000089-04_7_additional.jpg             0   \n",
       "...                                                 ...           ...   \n",
       "44074  WOMEN-Tees_Tanks-id_00007969-04_7_additional.jpg             1   \n",
       "44078  WOMEN-Tees_Tanks-id_00007970-01_7_additional.jpg             1   \n",
       "44082        WOMEN-Tees_Tanks-id_00007976-01_4_full.jpg             1   \n",
       "44086        WOMEN-Tees_Tanks-id_00007979-03_4_full.jpg             1   \n",
       "44091        WOMEN-Tees_Tanks-id_00007979-04_4_full.jpg             1   \n",
       "\n",
       "       lower_fabric  outer_fabric  upper_pattern  lower_pattern  \\\n",
       "0                 1             7              3              4   \n",
       "1                 1             7              3              3   \n",
       "2                 1             7              2              3   \n",
       "3                 1             7              3              3   \n",
       "4                 1             7              3              3   \n",
       "...             ...           ...            ...            ...   \n",
       "44074             1             0              3              0   \n",
       "44078             0             7              1              3   \n",
       "44082             0             7              6              3   \n",
       "44086             1             7              3              3   \n",
       "44091             1             7              3              3   \n",
       "\n",
       "       outer_pattern                        img_id img_num    img_view  \\\n",
       "0                  7         MEN-Denim-id_00000080      01  additional   \n",
       "1                  7         MEN-Denim-id_00000089      01  additional   \n",
       "2                  7         MEN-Denim-id_00000089      02  additional   \n",
       "3                  7         MEN-Denim-id_00000089      03  additional   \n",
       "4                  7         MEN-Denim-id_00000089      04  additional   \n",
       "...              ...                           ...     ...         ...   \n",
       "44074              3  WOMEN-Tees_Tanks-id_00007969      04  additional   \n",
       "44078              7  WOMEN-Tees_Tanks-id_00007970      01  additional   \n",
       "44082              7  WOMEN-Tees_Tanks-id_00007976      01        full   \n",
       "44086              7  WOMEN-Tees_Tanks-id_00007979      03        full   \n",
       "44091              7  WOMEN-Tees_Tanks-id_00007979      04        full   \n",
       "\n",
       "                                               segm_name  \n",
       "0         MEN-Denim-id_00000080-01_7_additional_segm.png  \n",
       "1         MEN-Denim-id_00000089-01_7_additional_segm.png  \n",
       "2         MEN-Denim-id_00000089-02_7_additional_segm.png  \n",
       "3         MEN-Denim-id_00000089-03_7_additional_segm.png  \n",
       "4         MEN-Denim-id_00000089-04_7_additional_segm.png  \n",
       "...                                                  ...  \n",
       "44074  WOMEN-Tees_Tanks-id_00007969-04_7_additional_s...  \n",
       "44078  WOMEN-Tees_Tanks-id_00007970-01_7_additional_s...  \n",
       "44082    WOMEN-Tees_Tanks-id_00007976-01_4_full_segm.png  \n",
       "44086    WOMEN-Tees_Tanks-id_00007979-03_4_full_segm.png  \n",
       "44091    WOMEN-Tees_Tanks-id_00007979-04_4_full_segm.png  \n",
       "\n",
       "[12701 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df7212f7-4727-4611-9e63-8d917d04f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv('full_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee0008-3b9f-4e52-997e-9efb4e5f32a7",
   "metadata": {},
   "source": [
    "# Split CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "576613e9-371a-4d71-8d81-3f9f070ddc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#80/10/10 train/val/test split with no data leakage of images with multiple poses\n",
    "\n",
    "group_shuffle_split_80_20 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=47)\n",
    "group_shuffle_split_50_50 = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=47)\n",
    "\n",
    "for train_index, temp_index in group_shuffle_split_80_20.split(data_df, groups=data_df['img_id']):\n",
    "    train_df = data_df.iloc[train_index]\n",
    "    temp_df = data_df.iloc[temp_index]\n",
    "\n",
    "for val_index, test_index in  group_shuffle_split_50_50.split(temp_df, groups=temp_df['img_id']):\n",
    "    val_df = temp_df.iloc[val_index]\n",
    "    test_df = temp_df.iloc[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96fe2a7c-d0ba-468e-934f-becd24436281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching image_ids found between any sets.\n"
     ]
    }
   ],
   "source": [
    "#Check for leakage:\n",
    "train_image_ids_set = set(train_df['img_id'])\n",
    "val_image_ids_set = set(val_df['img_id'])\n",
    "test_image_ids_set = set(test_df['img_id'])\n",
    "\n",
    "intersection_train_val = train_image_ids_set.intersection(val_image_ids_set)\n",
    "intersection_train_test = train_image_ids_set.intersection(test_image_ids_set)\n",
    "intersection_val_test = val_image_ids_set.intersection(test_image_ids_set)\n",
    "\n",
    "# Check if there are any matching image_ids between the sets\n",
    "if intersection_train_val:\n",
    "    print(\"Matching image_ids between train_set and val_set:\", intersection_train_val)\n",
    "\n",
    "if intersection_train_test:\n",
    "    print(\"Matching image_ids between train_set and test_set:\", intersection_train_test)\n",
    "\n",
    "if intersection_val_test:\n",
    "    print(\"Matching image_ids between val_set and test_set:\", intersection_val_test)\n",
    "else:\n",
    "    print(\"No matching image_ids found between any sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a2f884a-b8d2-46bd-9fc6-b015cc380339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to CSV:\n",
    "train_df.to_csv('train.csv')\n",
    "val_df.to_csv('val.csv')\n",
    "test_df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3afc049a-c1a1-4617-8e2b-78430be7fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make small datasources for model buidling:\n",
    "train_sample = train_df.sample(frac=0.1, random_state=47)\n",
    "val_sample = val_df.sample(frac=0.1, random_state=47)\n",
    "test_sample = test_df.sample(frac=0.1, random_state=47)\n",
    "\n",
    "train_sample.to_csv('train_sample.csv')\n",
    "val_sample.to_csv('val_sample.csv')\n",
    "test_sample.to_csv('test_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac84e6-f61d-4321-a0d9-0f6740ea8dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cbf6848-8622-490e-a90e-73d4741d705e",
   "metadata": {},
   "source": [
    "## Preprocess Image Segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a0123b6-ed9c-4b0d-afc9-2be97f726454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting and mapping PNG files: 100%|██████████| 12701/12701 [23:25<00:00,  9.04it/s]\n"
     ]
    }
   ],
   "source": [
    "mapping = {\n",
    "    1: 1,\n",
    "    2: 2,\n",
    "    3: 3,\n",
    "    5: 4,\n",
    "    6: 4,\n",
    "    4: 5,\n",
    "    21: 6\n",
    "}\n",
    "\n",
    "input_directory = '/vast/amr10211/cv_data/segm'\n",
    "output_directory = '/vast/amr10211/cv_data/segm_preprocessed'\n",
    "png_files = [filename for filename in os.listdir(input_directory) if filename.endswith('.png')]\n",
    "\n",
    "for filename in tqdm(png_files, desc=\"Converting and mapping PNG files\"):\n",
    "    input_filepath = os.path.join(input_directory, filename)\n",
    "    output_filepath = os.path.join(output_directory, filename)\n",
    "    \n",
    "    # Open the image\n",
    "    img = Image.open(input_filepath)\n",
    "    \n",
    "    # Convert the image to a NumPy array\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Apply the mapping to each pixel value\n",
    "    mapped_array = np.vectorize(lambda x: mapping.get(x, 0))(img_array)\n",
    "    \n",
    "    # Convert the mapped array back to an image\n",
    "    mapped_img = Image.fromarray(mapped_array.astype(np.uint8))\n",
    "    \n",
    "    # Save the mapped image as PNG\n",
    "    mapped_img.save(output_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf0597e4-dc6c-4f7e-87ea-03098867e184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting and mapping PNG files: 100%|██████████| 12701/12701 [02:56<00:00, 71.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: 0, Count: 9088520009\n",
      "Value: 1, Count: 400516322\n",
      "Value: 4, Count: 399366922\n",
      "Value: 2, Count: 191766313\n",
      "Value: 6, Count: 70451055\n",
      "Value: 5, Count: 277766047\n",
      "Value: 3, Count: 52070582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_directory = '/vast/amr10211/cv_data/segm_preprocessed'\n",
    "png_files = [filename for filename in os.listdir(input_directory) if filename.endswith('.png')]\n",
    "\n",
    "unique_value_counts = {}\n",
    "\n",
    "for filename in tqdm(png_files, desc=\"Converting and mapping PNG files\"):\n",
    "    input_filepath = os.path.join(input_directory, filename)\n",
    "    \n",
    "    # Open the image\n",
    "    img = Image.open(input_filepath)\n",
    "    \n",
    "    # Convert the image to a NumPy array\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    # Count unique values in the array\n",
    "    unique_values, counts = np.unique(img_array, return_counts=True)\n",
    "    \n",
    "    # Update the counts in the dictionary\n",
    "    for value, count in zip(unique_values, counts):\n",
    "        if value not in unique_value_counts:\n",
    "            unique_value_counts[value] = 0\n",
    "        unique_value_counts[value] += count\n",
    "\n",
    "# Print the final count per unique value\n",
    "for value, count in unique_value_counts.items():\n",
    "    print(f\"Value: {value}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6ea73-4f85-4fdb-a4b0-f1ea212948fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLM_env",
   "language": "python",
   "name": "dlm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
