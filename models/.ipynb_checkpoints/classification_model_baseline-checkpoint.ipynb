{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "575b54c1-df35-49b1-b503-971a8e234674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn.functional import relu\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import io\n",
    "import torch\n",
    "from skimage import color\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from PIL import Image, ImageOps\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee99e93-c50d-4d0a-91cf-b1f768c734be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('y')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564a6eac-65f5-4a80-aa8f-57a6bff6a5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Masking PNG files: 100%|██████████| 12701/12701 [25:45<00:00,  8.22it/s]\n"
     ]
    }
   ],
   "source": [
    "images_path = '/vast/amr10211/cv_data/images' \n",
    "train_path = '../data/full_data.csv'\n",
    "input_directory = '/vast/amr10211/cv_data/segm_preprocessed'\n",
    "output_directory = '/vast/amr10211/cv_data/masked_images'\n",
    "\n",
    "df = pd.read_csv(train_path)\n",
    "\n",
    "png_files = [filename for filename in os.listdir(input_directory) if filename.endswith('.png')]\n",
    "\n",
    "for file in tqdm.tqdm(png_files, desc=\"Masking PNG files\"):\n",
    "    segm_name = file\n",
    "    \n",
    "    img_name = df[df['segm_name'] == segm_name]['img_name'].iloc[0]\n",
    "    \n",
    "    image_filepath = os.path.join(images_path, img_name)\n",
    "    segm_filepath = os.path.join(input_directory, segm_name)\n",
    "    \n",
    "    image = Image.open(image_filepath)\n",
    "    segmentation = Image.open(segm_filepath)\n",
    "    \n",
    "    labels = [1,2,3,4,5,6]\n",
    "    \n",
    "    segmentation = np.array(segmentation)\n",
    "    for l in labels:\n",
    "        mask = np.where(segmentation == l, l, 0)\n",
    "    \n",
    "        if np.sum(mask) >= 5:\n",
    "            mask = np.repeat(mask[:, :, np.newaxis], 3, axis=2)\n",
    "            masked_image = np.multiply(image, mask)\n",
    "            \n",
    "            filename, file_extension = os.path.splitext(file)\n",
    "            output_filepath = filename + \"_\" + str(l) + file_extension\n",
    "            output_filepath = os.path.join(output_directory, output_filepath)\n",
    "            \n",
    "            masked_image = Image.fromarray(masked_image.astype(np.uint8))\n",
    "            masked_image.save(output_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a744d39b-949a-45bb-b527-6d2085592dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, segm_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file filename information.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.segm_dir = segm_dir\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir,\n",
    "                                self.data_frame.iloc[idx, 1])\n",
    "\n",
    "        segm_name = os.path.join(self.segm_dir,\n",
    "                                self.data_frame.iloc[idx, -1])\n",
    "\n",
    "        image = Image.open(img_name)\n",
    "        label = Image.open(segm_name)\n",
    "\n",
    "\n",
    "        #Convert to grayscale \n",
    "        # image = image.convert('L')\n",
    "        \n",
    "        #Resize image and label to 572x572\n",
    "        image = image.resize((572, 572))\n",
    "        label = label.resize((572, 572))\n",
    "\n",
    "        #Crop label to match probability output from model\n",
    "        crop = transforms.CenterCrop(388)\n",
    "        label = crop(label)\n",
    "\n",
    "        \n",
    "        #Normalize the image\n",
    "        image = np.asarray(image)\n",
    "        min_image = np.min(image)\n",
    "        max_image = np.max(image)\n",
    "        image = (image - min_image)/(max_image - min_image + 1e-4)\n",
    "        \n",
    "        #Convert to tensors\n",
    "        image = torch.tensor(np.array(image)).float().permute(2, 0, 1)\n",
    "        label = torch.tensor(np.array(label)).long()\n",
    "\n",
    "        #sample = {'x': , 'y': }\n",
    "        sample = {'x': image, 'y': label}\n",
    "    \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d16d9c-220b-4f6c-9453-00f98606ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.resnet18 = models.resnet18(weights=None) \n",
    "        num_ftrs = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Linear(num_ftrs, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet18(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLM_env",
   "language": "python",
   "name": "dlm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
